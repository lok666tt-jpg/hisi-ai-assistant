import streamlit as st
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain_classic.retrievers import EnsembleRetriever
from openai import OpenAI
import pickle
import jieba

st.set_page_config(page_title="å°å¾ã®ä¸šåŠ¡è°ƒåº¦å¤§è„‘", page_icon="âœˆï¸")
st.title("âœˆï¸ å°å¾ã®ä¸šåŠ¡è°ƒåº¦å¤§è„‘")
st.caption("å…¨é¢†åŸŸæŒ‚è½½ï¼šæ±‡é›†æˆ‘ç›®å‰é˜¶æ®µæ‰€æœ‰æ•´ç†å’Œå‚ä¸çš„é¡¹ç›®èµ„æ–™ï¼")

@st.cache_resource
def load_all_engines():
    embedding_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")
    
    # --- æŠ½å±‰ Aï¼šæœºåœºé¡¹ç›® (airport_vdb åŒå¼•æ“) ---
    airport_vector_db = Chroma(persist_directory="airport_vdb", embedding_function=embedding_model)
    airport_vector_retriever = airport_vector_db.as_retriever(search_kwargs={"k": 3})
    
    with open("airport_chunks.pkl", "rb") as f: airport_chunks = pickle.load(f)
    def jieba_tokenizer(text): return list(jieba.cut(text))
    airport_bm25_retriever = BM25Retriever.from_texts(airport_chunks, preprocess_func=jieba_tokenizer)
    airport_bm25_retriever.k = 3
    
    airport_ensemble = EnsembleRetriever(retrievers=[airport_bm25_retriever, airport_vector_retriever], weights=[0.5, 0.5])
    
    # --- æŠ½å±‰ Bï¼šåœ°æœç»´ä¿®é¡¹ç›® (ground_vdb çº¯å‘é‡å¼•æ“) ---
    ground_vector_db = Chroma(persist_directory="ground_vdb", embedding_function=embedding_model)
    ground_retriever = ground_vector_db.as_retriever(search_kwargs={"k": 3})
    
    return airport_ensemble, ground_retriever

airport_retriever, ground_retriever = load_all_engines()
client = OpenAI(api_key=st.secrets["DEEPSEEK_API_KEY"], base_url="https://api.deepseek.com")

if "messages" not in st.session_state: st.session_state.messages = []
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

def classify_intent(question):
    # ğŸ’¡ æå…¶ç¡¬æ ¸çš„ Promptï¼šå½»åº•åˆ†å¼€èˆªæ˜¾å’Œç»´ä¿®å¼€å•ï¼
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæå…¶èªæ˜çš„æœºåœºä¸šåŠ¡æ€»è°ƒåº¦å‘˜ã€‚
    è¯·åˆ¤æ–­ä¸‹é¢è¿™ä¸ªé—®é¢˜ï¼Œå±äºå“ªä¸ªä¸šåŠ¡é¢†åŸŸï¼š
    A: æœºåœºé¡¹ç›®ã€èˆªæ˜¾ç³»ç»Ÿ (HiSi-G.I.D.S)ã€ç»¼åˆæ˜¾ç¤ºç³»ç»Ÿã€å±å¹•å‚æ•°ã€æ¥å£è§„èŒƒ
    B: åœ°æœå…¬å¸é¡¹ç›®ã€è½¦è¾†ç»´ä¿®ã€ç»´ä¿®å¼€å•ã€ç†èµ”ã€ç™»æœºæ¡¥ç»´ä¿ã€æ–½å·¥ç®¡ç†ã€å·¥æ—¶åˆ†é…
    
    ä½ åªèƒ½å›ç­”ä¸€ä¸ªå¤§å†™å­—æ¯ 'A' æˆ– 'B'ï¼Œç»å¯¹ä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ ‡ç‚¹æˆ–åºŸè¯ã€‚
    ç”¨æˆ·é—®é¢˜ï¼š{question}"""
    
    response = client.chat.completions.create(model="deepseek-chat", messages=[{"role": "user", "content": prompt}], temperature=0)
    return response.choices[0].message.content.strip()

if prompt := st.chat_input("è·¨ç•Œæ‹·é—®ï¼ˆä¾‹ï¼šå…ˆé—®èˆªæ˜¾å‚æ•°ï¼Œå†é—®ç»´ä¿®å¼€å•å·¥æ—¶ï¼‰..."):
    with st.chat_message("user"): st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        intent = classify_intent(prompt)
        
        if "A" in intent:
            st.caption("ğŸ¤– *è°ƒåº¦å‘˜ -> é”å®šä¸ºã€æœºåœºé¡¹ç›®/èˆªæ˜¾ã€‘ï¼Œå¯åŠ¨æŠ½å±‰ A åŒå¼•æ“æ£€ç´¢...*")
            docs = airport_retriever.invoke(prompt)
        elif "B" in intent:
            st.caption("ğŸ¤– *è°ƒåº¦å‘˜ -> é”å®šä¸ºã€åœ°æœé¡¹ç›®/ç»´ä¿ã€‘ï¼Œå¯åŠ¨æŠ½å±‰ B ä¸“å±æ£€ç´¢...*")
            docs = ground_retriever.invoke(prompt)
        else:
            st.caption("ğŸ¤– *è°ƒåº¦å‘˜é‡åˆ°æœªçŸ¥é¢†åŸŸï¼Œé»˜è®¤å»æŠ½å±‰ A ç¢°è¿æ°”...*")
            docs = airport_retriever.invoke(prompt)
            
        context = "\n\n".join([doc.page_content for doc in docs])
        
        api_messages = [{"role": "system", "content": "ä½ æ˜¯æå…¶ä¸¥è°¨çš„ä¸šåŠ¡ä¸“å®¶ã€‚è¯·ç»“åˆã€å‚è€ƒçŸ¥è¯†åº“ã€‘å›ç­”ã€‚å¦‚æœªæåŠç›´æ¥å›ç­”ä¸çŸ¥é“ã€‚"}]
        for msg in st.session_state.messages[:-1]: api_messages.append({"role": msg["role"], "content": msg["content"]})
        api_messages.append({"role": "user", "content": f"ã€å‚è€ƒçŸ¥è¯†åº“ã€‘\n{context}\n\nã€æœ€æ–°é—®é¢˜ã€‘\n{prompt}"})
        
        response = client.chat.completions.create(model="deepseek-chat", messages=api_messages, stream=False)
        answer = response.choices[0].message.content
        st.markdown(answer)
        st.session_state.messages.append({"role": "assistant", "content": answer})










